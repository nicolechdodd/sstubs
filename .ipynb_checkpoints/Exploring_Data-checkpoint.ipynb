{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd5dc6b-2dd4-498f-b7d6-abaabc14460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd    \n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from git import Repo\n",
    "from git import GitCommandError\n",
    "import git\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ea8567-afab-4cb9-865b-d540c4524b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dump_jsonl(data, output_path, append=False):\n",
    "    \"\"\"\n",
    "    Write list of objects to a JSON lines file.\n",
    "    \"\"\"\n",
    "    mode = 'a+' if append else 'w'\n",
    "    with open(output_path, mode, encoding='utf-8') as f:\n",
    "        for line in data:\n",
    "            json_record = json.dumps(line, ensure_ascii=False)\n",
    "            f.write(json_record + '\\n')\n",
    "    print('Wrote {} records to {}'.format(len(data), output_path))\n",
    "\n",
    "\n",
    "def load_jsonl(input_path) -> list:\n",
    "    \"\"\"\n",
    "    Read list of objects from a JSON lines file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f121b2-2729-47cd-af33-0bfd08cd623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_projs(x):\n",
    "    return '.'.join(x.split('/')[-2:])\n",
    "\n",
    "with open('./sstubsLarge','rb') as fp:\n",
    "    sstubs = json.load(fp)\n",
    "stubs_df = pd.DataFrame(sstubs)\n",
    "top_projs = pd.read_csv('./topProjects.csv')\n",
    "repos_series = top_projs.repository_url.apply(add_projs)\n",
    "top_projs['projectName'] =repos_series\n",
    "stubs_df_m = stubs_df.merge(top_projs, on='projectName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af2f759f-4925-4f93-b866-31da66559aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many characters to consider on either side of the patch (heuristic)\n",
    "window_size = 512\n",
    "def run_parallel(row):\n",
    "    dir_name = './repos/'+'/'.join(row.projectName.split('.') )\n",
    "    if not os.path.isdir(dir_name):\n",
    "        return None\n",
    "    #     repo = Repo.clone_from('https://github.com/'+'/'.join(row.projectName.split('.')), dir_name)\n",
    "    # else:\n",
    "    \n",
    "    try:\n",
    "        #get basic info\n",
    "        repo = Repo(dir_name)\n",
    "        commit_before = repo.commit(row.fixCommitParentSHA1)\n",
    "        commit_after = repo.commit(row.fixCommitSHA1)\n",
    "\n",
    "        filea = commit_before.tree[row.bugFilePath].data_stream.read()\n",
    "        fileb = commit_after.tree[row.bugFilePath].data_stream.read()\n",
    "        window_context = filea[max(row.bugNodeStartChar-window_size,0):min(row.bugNodeStartChar+row.bugNodeLength+window_size,len(filea))].decode()\n",
    "        row['source_before_fix_minedbyKevin'] = str(filea[row.bugNodeStartChar:row.bugNodeStartChar+row.bugNodeLength])\n",
    "        row['source_after_fix_minedbyKevin'] = str(fileb[row.fixNodeStartChar:row.fixNodeStartChar+row.fixNodeLength])\n",
    "        row['source_before'] = str(filea)\n",
    "        row['source_after'] = str(fileb)\n",
    "        row['author_before'] = str(commit_before.author.email)\n",
    "        row['author_after'] = str(commit_after.author.email)\n",
    "        row['author_date_commit_before'] = str(commit_before.authored_date) #won't be super informative\n",
    "        row['author_date_commit_after'] = str(commit_after.authored_date)\n",
    "        \n",
    "        #get extra oldest commit with window of context\n",
    "        loginfo = repo.git.log('--all','-p','--reverse','--source','-S', window_context, '--',str(row.bugFilePath))\n",
    "        oldest_commit = None\n",
    "\n",
    "        #extract the oldest commit from the git log info\n",
    "        c_line = loginfo.splitlines()[0]\n",
    "        if 'commit' not in c_line:\n",
    "            return None\n",
    "        oldest_commit = c_line.split()[1]\n",
    "        oldest_commit_obj = repo.commit(oldest_commit)\n",
    "\n",
    "        # oldest_commit_contents = repo.git.show('{}:{}'.format(oldest_commit, row.bugFilePath))\n",
    "        oldest_commit_contents = oldest_commit_obj.tree[row.bugFilePath].data_stream.read()\n",
    "        number_of_commits = repo.git.rev_list('--count', oldest_commit+'..'+str(row.fixCommitSHA1))\n",
    "\n",
    "        row['oldest_commit'] = str(oldest_commit)\n",
    "        row['source_oldest_commit'] = str(oldest_commit_contents)\n",
    "        row['author_oldest_commit'] = str(oldest_commit_obj.author.email)\n",
    "        row['author_date_oldest_commit'] = str(oldest_commit_obj.authored_date)\n",
    "        row['number_of_commits_oldest'] = str(number_of_commits)\n",
    "\n",
    "    except Exception as ee:\n",
    "        # with so many different errors between various commits and branches\n",
    "        # it does not make sense to try to handle them for only 1.4% of failures in the dataset\n",
    "        return None\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3390925e-1da8-42fc-abfb-44085cbd619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "L = Parallel(n_jobs=32)(delayed(run_parallel)(row) for i, row in stubs_df_m.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d03f10d-8d77-421e-a71b-1391f3bd52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = [git_item.to_dict() for git_item in L if git_item is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fc18ddc-4781-49b5-a06e-e792298a59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv=True\n",
    "if csv:\n",
    "    pd.DataFrame(final).to_csv('./mined_data_sstubs_feb3.csv')\n",
    "else:\n",
    "    dump_jsonl(final, './mined_data_sstubs_feb3.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf979482-3980-4f6d-b444-8f9d6fa91f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used this to premptively list all github urls. In bash I use xargs to git clone all the projects in parallel\n",
    "# with open('x_args_github.txt', 'w') as f:\n",
    "#     l = []\n",
    "#     for i, row in stubs_df_m.iterrows():\n",
    "#         dir_name = './repos/'+'/'.join(row.projectName.split('.') )\n",
    "#         # if not os.path.isdir(dir_name):\n",
    "#         #     repo = Repo.clone_from('https://github.com/'+'/'.join(row.projectName.split('.')), dir_name)\n",
    "\n",
    "#         l.append('git clone https://github.com/'+'/'.join(row.projectName.split('.'))+' '+dir_name)\n",
    "#     l = list(set(l))\n",
    "#     for element in l:\n",
    "#         f.write(element + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2c8b11d-d5a5-47f8-905f-ebb39caaae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fileInRepo(repo, filePath, commit):\n",
    "#     '''\n",
    "#     Useful feature but is not used in final function\n",
    "#     '''\n",
    "#     pathdir = os.path.dirname(filePath)\n",
    "#     # Build up reference to desired repo path\n",
    "#     rsub = repo.commit(commit).tree\n",
    "#     for path_element in pathdir.split(os.path.sep):\n",
    "#         # If dir on file path is not in repo, neither is file. \n",
    "#         try : \n",
    "#             rsub = rsub[path_element]\n",
    "#         except KeyError : \n",
    "#             return False\n",
    "#     return(filePath in rsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb764391-0ec3-4358-9521-8b053fb131ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "## Ignore, this is an iterative implementation to ensure the parallel one works too. It is very slow\n",
    "## because it is sequential\n",
    "#\n",
    "\n",
    "# stubs_df_kevin_edits = []\n",
    "# import time\n",
    "# st = time.time()\n",
    "# conts = 0\n",
    "# window_size=512\n",
    "# for i, row in tqdm.tqdm(stubs_df_m.iloc[:100].iterrows()):\n",
    "#     # print(\"ITER\")\n",
    "#     try:\n",
    "#         dir_name = './repos/'+'/'.join(row.projectName.split('.') )\n",
    "#         if not os.path.isdir(dir_name):\n",
    "#             continue\n",
    "#         #     repo = Repo.clone_from('https://github.com/'+'/'.join(row.projectName.split('.')), dir_name)\n",
    "#         # else:\n",
    "#         repo = Repo(dir_name)\n",
    "#         commit_before = repo.commit(row.fixCommitParentSHA1)\n",
    "#         commit_after = repo.commit(row.fixCommitSHA1)\n",
    "\n",
    "\n",
    "#         filea = commit_before.tree[row.bugFilePath].data_stream.read()\n",
    "#         fileb = commit_after.tree[row.bugFilePath].data_stream.read()\n",
    "#         window_context = filea[max(row.bugNodeStartChar-window_size,0):min(row.bugNodeStartChar+row.bugNodeLength+window_size,len(filea))].decode()\n",
    "#         row['source_before_fix_minedbyKevin'] = str(filea[row.bugNodeStartChar:row.bugNodeStartChar+row.bugNodeLength])\n",
    "#         row['source_after_fix_minedbyKevin'] = str(fileb[row.fixNodeStartChar:row.fixNodeStartChar+row.fixNodeLength])\n",
    "#         row['source_before'] = str(filea)\n",
    "#         row['source_after'] = str(fileb)\n",
    "#         row['author_before'] = str(commit_before.author.email)\n",
    "#         row['author_after'] = str(commit_after.author.email)\n",
    "#         row['author_date_commit_before'] = str(commit_before.authored_date) #won't be super informative\n",
    "#         row['author_date_commit_after'] = str(commit_after.authored_date)\n",
    "\n",
    "#         #loginfo = repo.git.log('--all','-p','--reverse','--source','-S', str(row.sourceBeforeFix), '--',str(row.bugFilePath))\n",
    "#         print(window_context)\n",
    "#         loginfo = repo.git.log('--all','-p','--reverse','--source','-S', window_context, '--',str(row.bugFilePath))\n",
    "#         print(loginfo)\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "#         oldest_commit = None\n",
    "#         try:\n",
    "#             c_line = loginfo.splitlines()[0]\n",
    "#             if 'commit' not in c_line:\n",
    "#                 continue\n",
    "#         except IndexError as e:\n",
    "#             continue\n",
    "\n",
    "#         if 'commit' in c_line:\n",
    "#             oldest_commit = c_line.split()[1]\n",
    "\n",
    "#         if not oldest_commit:\n",
    "#             continue\n",
    "#         oldest_commit_obj = repo.commit(oldest_commit)\n",
    "#         try:\n",
    "#         # oldest_commit_contents = repo.git.show('{}:{}'.format(oldest_commit, row.bugFilePath))\n",
    "#             oldest_commit_contents = oldest_commit_obj.tree[row.bugFilePath].data_stream.read()\n",
    "#             number_of_commits = repo.git.rev_list('--count', oldest_commit+'..'+str(row.fixCommitSHA1))\n",
    "#         except Exception as ee:\n",
    "#             print(ee)\n",
    "#             continue\n",
    "#             # return None\n",
    "\n",
    "#         row['oldest_commit'] = str(oldest_commit)\n",
    "#         row['source_oldest_commit'] = str(oldest_commit_contents)\n",
    "#         row['author_oldest_commit'] = str(oldest_commit_obj.author.email)\n",
    "#         row['author_date_oldest_commit'] = str(oldest_commit_obj.authored_date)\n",
    "#         row['number_of_commits_oldest'] = str(number_of_commits)\n",
    "\n",
    "#         stubs_df_kevin_edits.append(row)\n",
    "#     except Exception as ee:\n",
    "#         print(ee)\n",
    "#         continue\n",
    "# tot = time.time()-st\n",
    "# print(tot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
